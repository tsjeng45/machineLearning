{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20210805機器學習教師研習_完成檔.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aHuZ9JFphY0x",
        "ektmJJbyvtVk",
        "Oh9QlsEzDLSy",
        "MPydcJ8vQ8aD",
        "h0-dRnpigbvV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHuZ9JFphY0x"
      },
      "source": [
        "## 手寫數字辨識"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo9SvX41qrkC"
      },
      "source": [
        "### 手寫數字辨識程式碼\n",
        "```\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(20, input_dim=784, activation='relu'))\n",
        "model.add(Dense(40, activation='relu'))\n",
        "model.add(Dense(80, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='mse', optimizer=SGD(learning_rate=0.05), metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, validation_split=0.2, batch_size=100, epochs=20)\n",
        "\n",
        "predict = np.argmax(model.predict(x_test), axis=-1)\n",
        "\n",
        "score = model.evaluate(x_test, y_test)\n",
        "print('正確率', score[1])\n",
        "\n",
        "model.save('number.h5')\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/number.h5')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY_PDGWwgVBX"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QpjtvzVhVmV"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfrsYzy7O1ZN"
      },
      "source": [
        "x_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdgmDqB4PFAo"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUHkQmD_PgLg"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQcOHCQWPzQb"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxBi44T4P-Tw"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7Rs4SYSQRgq"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvRjIWo1Qh8c"
      },
      "source": [
        "plt.imshow(x_train[0], cmap='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfMdWVaeQe5Y"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFQoxpf_SSnX"
      },
      "source": [
        "x_train = x_train.reshape(60000, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTA3OJCoSxSV"
      },
      "source": [
        "x_test = x_test.reshape(10000, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4og6JduTY_W"
      },
      "source": [
        "x_train = x_train / 255\n",
        "x_test = x_test / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht7HCKFPYqnO"
      },
      "source": [
        "y_train = to_categorical(y_train, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVko7JV5DdCX"
      },
      "source": [
        "y_train[2] #one-hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emkcEV3SDo3F"
      },
      "source": [
        "y_test = to_categorical(y_test, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x49l35tjE2QQ"
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBrPwpZ0FMu0"
      },
      "source": [
        "model.add(Dense(20, input_dim=784, activation='relu')) #sigmoid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlg1fhrcGaWf"
      },
      "source": [
        "model.add(Dense(40, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEKfZ8M9GyyG"
      },
      "source": [
        "model.add(Dense(80, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTFhFMG6G4-t"
      },
      "source": [
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzc8KLwgHT_h"
      },
      "source": [
        "model.compile(loss='mse', optimizer=SGD(learning_rate=0.05), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nr5SzWdIxD9"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sTzoWnWKYRN"
      },
      "source": [
        "model.fit(x_train, y_train, validation_batch_size=0.2, batch_size=100, epochs=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgGWMQkuLNWR"
      },
      "source": [
        "score = model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O4vui-YMq2V"
      },
      "source": [
        "predict = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAdObKVgNjKf"
      },
      "source": [
        "predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2VAkeUgQebk"
      },
      "source": [
        "predict = model.predict(x_test)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPWXW5HzQjfD"
      },
      "source": [
        "predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLb-3ykbRSlV"
      },
      "source": [
        "predict = np.argmax(model.predict(x_test)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xipxhx7JRoH1"
      },
      "source": [
        "predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_JpjhP9SVRh"
      },
      "source": [
        "model.save('number.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw8IrxarSoXB"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/number.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGu6cNWSTlYa"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        " \n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        " \n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        " \n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        " \n",
        "model = Sequential()\n",
        "model.add(Dense(20, input_dim=784, activation='relu'))\n",
        "model.add(Dense(40, activation='relu'))\n",
        "model.add(Dense(80, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        " \n",
        "model.compile(loss='mse', optimizer=SGD(learning_rate=0.05), metrics=['accuracy'])\n",
        " \n",
        "model.fit(x_train, y_train, validation_split=0.2, batch_size=100, epochs=20)\n",
        " \n",
        "predict = np.argmax(model.predict(x_test), axis=-1)\n",
        " \n",
        "score = model.evaluate(x_test, y_test)\n",
        "print('正確率', score[1])\n",
        " \n",
        "model.save('number.h5')\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/number.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ektmJJbyvtVk"
      },
      "source": [
        "## gradio：網頁互動界面"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UckXjSlv0Aux"
      },
      "source": [
        "### gradio程式碼\n",
        "**手寫數字**\n",
        "```\n",
        "!pip install gradio\n",
        "\n",
        "import gradio as gr\n",
        "import tensorflow\n",
        "\n",
        "model = tensorflow.keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/number.h5\")\n",
        "\n",
        "def mnist(image):\n",
        "    image = image.reshape(1, 784)\n",
        "    prediction = model.predict(image).tolist()[0]\n",
        "    return {str(i): prediction[i] for i in range(10)}\n",
        "\n",
        "grobj = gr.Interface(fn=mnist, inputs=\"sketchpad\", outputs=gr.outputs.Label(num_top_classes=3, label='預測結果'), title=\"手寫數字\")\n",
        "grobj.launch()\n",
        "```\n",
        "**Inception辨識物體**\n",
        "```\n",
        "import gradio as gr\n",
        "import tensorflow\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "model = tensorflow.keras.applications.InceptionV3()\n",
        "\n",
        "response = requests.get('https://git.io/JJkYN')\n",
        "\n",
        "labels = response.text.split('\\n')\n",
        "\n",
        "def classify(img):\n",
        "    img = np.expand_dims(img, 0)\n",
        "    img = tensorflow.keras.applications.inception_v3.preprocess_input(img)\n",
        "    prediction = model.predict(img)[0]\n",
        "    return {labels[i]: float(prediction[i]) for i in range(len(prediction))}\n",
        "\n",
        "imputs = gr.inputs.Image(shape=(299, 299))\n",
        "\n",
        "outputs = gr.outputs.Label(num_top_classes=3, label='預測結果')\n",
        "\n",
        "grobj = gr.Interface(fn=classify, inputs=imputs, outputs=outputs, title='Inception物件偵測')\n",
        "grobj.launch()\n",
        "```\n",
        "**自動歌詞產生器(繁體)** \n",
        "```\n",
        "import gradio as gr\n",
        "grobj = gr.Interface.load(\"huggingface/uer/gpt2-chinese-lyric\", inputs=\"text\", outputs=\"text\")\n",
        "grobj.launch()\n",
        "\n",
        "!pip install opencc\n",
        "!pip install transformers\n",
        "\n",
        "import gradio as gr\n",
        "from opencc import OpenCC\n",
        "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
        "\n",
        "cc = OpenCC('s2twp')\n",
        "\n",
        "def lyric(text):\n",
        "    text_generator = TextGenerationPipeline(model, tokenizer)\n",
        "    ret = text_generator(text, max_length=100, do_sample=True)\n",
        "    return cc.convert(ret[0]['generated_text'])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ezlEBkcmV_k"
      },
      "source": [
        "### 手寫數字"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8VePQb3wHxs"
      },
      "source": [
        "!pip install gradio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJd8FqG4XgDq"
      },
      "source": [
        "import gradio as gr\n",
        "import tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIln3eEcX0_I"
      },
      "source": [
        "model = tensorflow.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/number.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nB4BNT2YcGF"
      },
      "source": [
        "def mnist(image):\n",
        "  image = image.reshape(1, 784)   #(1, 28, 28)\n",
        "  prediction = model.predict(image).tolist()[0]\n",
        "  ret = {}\n",
        "  for i in range(10):  #{'0':0.05,}\n",
        "    ret[str(i)] = prediction[i]\n",
        "  return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71Z76VkhY3vV"
      },
      "source": [
        "grobj = gr.Interface(fn=mnist, inputs='sketchpad', outputs=gr.outputs.Label(num_top_classes=5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUX8_GsVagCo"
      },
      "source": [
        "grobj.launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p98f6Ykeznzi"
      },
      "source": [
        "from urllib.request import urlretrieve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAUk1uKR0it1"
      },
      "source": [
        "urlretrieve(\"https://gr-models.s3-us-west-2.amazonaws.com/mnist-model.h5\", \"mnist-model.h5\")\n",
        "model = tensorflow.keras.models.load_model(\"mnist-model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ub16UDGmeD7"
      },
      "source": [
        "### Inception辨識物體"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr6VXJXbSQ9M"
      },
      "source": [
        "import gradio as gr\n",
        "import tensorflow\n",
        "import numpy as np\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeFO9N77UZTN"
      },
      "source": [
        "model = tensorflow.keras.applications.InceptionV3()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuzHRg_Lk7QL"
      },
      "source": [
        "response = requests.get('https://git.io/JJkYN')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLLlf7pil9Os"
      },
      "source": [
        "response.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqyF7uY3mC99"
      },
      "source": [
        "labels = response.text.split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbNe8U5Vm1ma"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxM50YXtm4UW"
      },
      "source": [
        "def classify(img):\n",
        "  img = np.expand_dims(img, 0) #(299, 299, 3)\n",
        "  img = tensorflow.keras.applications.inception_v3.preprocess_input(img)\n",
        "  prediction = model.predict(img)[0]\n",
        "  ret = {}\n",
        "  for i in range(len(prediction)):\n",
        "    ret[labels[i]] = float(prediction[i])\n",
        "  return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMht-yRf-gB8"
      },
      "source": [
        "img = gr.inputs.Image(shape=(299, 299), label='輸入圖片')\n",
        "out = gr.outputs.Label(num_top_classes=3, label='預測結果')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex2uM9nL_dx0"
      },
      "source": [
        "grobj = gr.Interface(fn=classify, inputs=img, outputs=out, title='Inception物體辨識')\n",
        "grobj.launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpAFtzldsrwf"
      },
      "source": [
        "### 自動歌詞產生器(繁體)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G483ovQTUwzV"
      },
      "source": [
        "import gradio as gr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X73BMZ2TG-OD"
      },
      "source": [
        "grobj = gr.Interface.load('huggingface/uer/gpt2-chinese-lyric', inputs='text', outputs='text')\n",
        "grobj.launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9onhdbl2phfV"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrZwJDYgJHPH"
      },
      "source": [
        "!pip install opencc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T80ZnoCCJWEM"
      },
      "source": [
        "from opencc import OpenCC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jfao2zibJwUw"
      },
      "source": [
        "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyXSkxNBJ8_N"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-lyric\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJF2TTZ7KGOX"
      },
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-lyric\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cte0TDrhLsO1"
      },
      "source": [
        "cc = OpenCC('s2twp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEE8HtX-Jygm"
      },
      "source": [
        "def lyric(text):\n",
        "  text_generator = TextGenerationPipeline(model, tokenizer)\n",
        "  ret = text_generator(text, max_length=100, do_sample=False)\n",
        "  return cc.convert(ret[0]['generated_text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kEXjO8QrCUB"
      },
      "source": [
        "grobj = gr.Interface(fn=lyric,inputs=\"textbox\", outputs=gr.outputs.Textbox(), title=\"自動產生歌詞\")\n",
        "grobj.launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh9QlsEzDLSy"
      },
      "source": [
        "## Teachable Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJxTShAzQnoX"
      },
      "source": [
        "import tensorflow.keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "\n",
        "# Disable scientific notation for clarity\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# Load the model\n",
        "model = tensorflow.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/keras_model.h5')\n",
        "\n",
        "# Create the array of the right shape to feed into the keras model\n",
        "# The 'length' or number of images you can put into the array is\n",
        "# determined by the first position in the shape tuple, in this case 1.\n",
        "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "\n",
        "# Replace this with the path to your image\n",
        "image = Image.open('/content/drive/MyDrive/Colab Notebooks/cloth1.jpg')\n",
        "\n",
        "#resize the image to a 224x224 with the same strategy as in TM2:\n",
        "#resizing the image to be at least 224x224 and then cropping from the center\n",
        "size = (224, 224)\n",
        "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
        "\n",
        "#turn the image into a numpy array\n",
        "image_array = np.asarray(image)\n",
        "\n",
        "# display the resized image\n",
        "#image.show()\n",
        "\n",
        "# Normalize the image\n",
        "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
        "\n",
        "# Load the image into the array\n",
        "data[0] = normalized_image_array\n",
        "\n",
        "# run the inference\n",
        "prediction = model.predict(data)\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRnMVCzfJQ6B"
      },
      "source": [
        "### Teachable Machine程式碼\n",
        "```\n",
        "# 使用攝影機控制圓點移動\n",
        "import numpy as np\n",
        "import cv2\n",
        "from time import sleep\n",
        "import tensorflow.keras\n",
        " \n",
        "labels = ['cloth','fist','nothing']\n",
        "current_x = 300\n",
        "move = 10\n",
        "model = tensorflow.keras.models.load_model('keras_model.h5')\n",
        " \n",
        "cap = cv2.VideoCapture(0)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "while True:\n",
        "    success, image = cap.read()\n",
        "    if success == True:\n",
        "        data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "        image = cv2.flip(image,1) #左右反轉\n",
        "        img = cv2.resize(image,(224,224))\n",
        "        img = np.array(img,dtype=np.float32)\n",
        "        img = np.expand_dims(img,axis=0)\n",
        "        img = (img/127.0) - 1 #正規化\n",
        "        data[0] = img\n",
        " \n",
        "        prediction = model.predict(data) #預測\n",
        "        predicted_class = np.argmax(prediction[0], axis=-1)\n",
        "        predicted_class_name = labels[predicted_class]\n",
        "        print(current_x, predicted_class_name)\n",
        " \n",
        "        if predicted_class_name == 'cloth':\n",
        "            current_x -= move\n",
        "            if current_x < 0:\n",
        "                current_x = 0\n",
        "        elif predicted_class_name == 'fist':\n",
        "            current_x += move\n",
        "            if current_x > width:\n",
        "                current_x = width\n",
        "        cv2.putText(image, 'O', (current_x,100), cv2.FONT_HERSHEY_PLAIN, 0.4, (255, 0, 0), cv2.LINE_AA)\n",
        "        cv2.imshow(\"Frame\",image)\n",
        "        sleep(0.2)\n",
        " \n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        " \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()    \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPydcJ8vQ8aD"
      },
      "source": [
        "## cvzone：多媒體機器學習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfxgP48AR_ns"
      },
      "source": [
        "### cvzone程式碼\n",
        "```\n",
        "!pip install cvzone\n",
        "!pip install mediapipe\n",
        "\n",
        "#臉部偵測\n",
        "from cvzone.FaceDetectionModule import FaceDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/person1.jpg')\n",
        "detector = FaceDetector()\n",
        "img, bboxs = detector.findFaces(img)\n",
        "#print('人臉範圍：', bboxs)\n",
        "cv2_imshow(img)\n",
        "\n",
        "#臉部特徵網\n",
        "from cvzone.FaceMeshModule import FaceMeshDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/person1.jpg')\n",
        "detector = FaceMeshDetector(staticMode=True, maxFaces=5)\n",
        "img, faces = detector.findFaceMesh(img)\n",
        "cv2_imshow(img)\n",
        "\n",
        "#手部偵測\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/hand1.jpg')\n",
        "detector = HandDetector(mode=False, detectionCon=0.5, maxHands=2)\n",
        "img = detector.findHands(img)\n",
        "cv2_imshow(img)\n",
        "\n",
        "#姿勢偵測\n",
        "from cvzone.PoseModule import PoseDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/pose1.jpg')\n",
        "detector = PoseDetector()\n",
        "img = detector.findPose(img)\n",
        "cv2_imshow(img)\n",
        "\n",
        "#手部攝影追踪\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "detector = HandDetector()\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    img = cv2.flip(img, 1)\n",
        "    img = detector.findHands(img)\n",
        "    cv2.imshow(\"Image\", img)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHhnlE4-RnwA"
      },
      "source": [
        "!pip install cvzone"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGGHazvRYwIp"
      },
      "source": [
        "!pip install mediapipe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqqZbppTRF5C"
      },
      "source": [
        "#臉部偵測\n",
        "from cvzone.FaceDetectionModule import FaceDetector\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrBP20lEZuCo"
      },
      "source": [
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/person1.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIotgH-caEi2"
      },
      "source": [
        "detector = FaceDetector()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZg65WuPaPVr"
      },
      "source": [
        "img, bboxs = detector.findFaces(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3JmxjjVagrx"
      },
      "source": [
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjlR0IY0RTx2"
      },
      "source": [
        "#臉部特徵網\n",
        "from cvzone.FaceMeshModule import FaceMeshDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/person1.jpg')\n",
        "detector = FaceMeshDetector(staticMode=True, maxFaces=5)\n",
        "img, faces = detector.findFaceMesh(img)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDfNTnaERX1i"
      },
      "source": [
        "#手部偵測\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/hand1.jpg')\n",
        "detector = HandDetector()\n",
        "img = detector.findHands(img)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uet0vG-1RzSm"
      },
      "source": [
        "#姿勢偵測\n",
        "from cvzone.PoseModule import PoseDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/pose1.jpg')\n",
        "detector = PoseDetector()\n",
        "img = detector.findPose(img)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDrFF6V8R3EB"
      },
      "source": [
        "#手部狀態偵測\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/hand2.jpg')\n",
        "detector = HandDetector(mode=False, detectionCon=0.5)\n",
        "img = detector.findHands(img)\n",
        "lmList, bboxInfo = detector.findPosition(img)\n",
        "#print('特徵點：', lmList)\n",
        "if lmList:\n",
        "  bbox = bboxInfo['bbox']\n",
        "  #左右手\n",
        "  myHandType = detector.handType() \n",
        "  cv2.putText(img, 'Hand:{}'.format(myHandType), (bbox[0], bbox[1]-25), cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), 2)\n",
        "  #伸出手指數\n",
        "  fingers = detector.fingersUp()\n",
        "  #print(fingers)\n",
        "  upFingers = fingers.count(1)\n",
        "  cv2.putText(img, 'Finger:{}'.format(upFingers), (bbox[0]+100, bbox[1]-25), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 2)\n",
        "  #兩特徵點距離\n",
        "  distance, img, info = detector.findDistance(8, 12, img) #食指與中指\n",
        "  cv2.putText(img, 'Dist:{}'.format(str(int(distance))), (bbox[0]+200, bbox[1]-25), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0-dRnpigbvV"
      },
      "source": [
        "## 滑桿式BMI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qrWTpecgg3S"
      },
      "source": [
        "!pip install gradio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpKWgwZRglTW"
      },
      "source": [
        "import gradio as gr\n",
        "\n",
        "def calBMI(height, weight):\n",
        "  bmi = weight / (height / 100) ** 2\n",
        "  return round(bmi, 2)\n",
        "\n",
        "height = gr.inputs.Slider(minimum=100, maximum=220, step=1, default=160, label=\"身高 (公分)\")\n",
        "weight = gr.inputs.Slider(minimum=20, maximum=200, step=1, default=60, label=\"體重 (公斤)\")\n",
        "grobj = gr.Interface(fn=calBMI, inputs=[height, weight], outputs='text', title='BMI值', live=True)\n",
        "grobj.launch()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}