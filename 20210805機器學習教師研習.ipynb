{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20210805機器學習教師研習.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aHuZ9JFphY0x",
        "ektmJJbyvtVk",
        "Oh9QlsEzDLSy",
        "MPydcJ8vQ8aD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHuZ9JFphY0x"
      },
      "source": [
        "## 手寫數字辨識"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo9SvX41qrkC"
      },
      "source": [
        "### 手寫數字辨識程式碼\n",
        "```\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(20, input_dim=784, activation='relu'))\n",
        "model.add(Dense(40, activation='relu'))\n",
        "model.add(Dense(80, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='mse', optimizer=SGD(learning_rate=0.05), metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, validation_split=0.2, batch_size=100, epochs=20)\n",
        "\n",
        "predict = np.argmax(model.predict(x_test), axis=-1)\n",
        "\n",
        "score = model.evaluate(x_test, y_test)\n",
        "print('正確率', score[1])\n",
        "\n",
        "model.save('number.h5')\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/number.h5')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY_PDGWwgVBX"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QpjtvzVhVmV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ektmJJbyvtVk"
      },
      "source": [
        "## gradio：網頁互動界面"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UckXjSlv0Aux"
      },
      "source": [
        "### gradio程式碼\n",
        "**手寫數字**\n",
        "```\n",
        "!pip install gradio\n",
        "\n",
        "import gradio as gr\n",
        "import tensorflow\n",
        "\n",
        "model = tensorflow.keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/number.h5\")\n",
        "\n",
        "def mnist(image):\n",
        "    image = image.reshape(1, 784)\n",
        "    prediction = model.predict(image).tolist()[0]\n",
        "    return {str(i): prediction[i] for i in range(10)}\n",
        "\n",
        "grobj = gr.Interface(fn=mnist, inputs=\"sketchpad\", outputs=gr.outputs.Label(num_top_classes=3, label='預測結果'), title=\"手寫數字\")\n",
        "grobj.launch()\n",
        "```\n",
        "**Inception辨識物體**\n",
        "```\n",
        "import gradio as gr\n",
        "import tensorflow\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "model = tensorflow.keras.applications.InceptionV3()\n",
        "\n",
        "response = requests.get('https://git.io/JJkYN')\n",
        "\n",
        "labels = response.text.split('\\n')\n",
        "\n",
        "def classify(img):\n",
        "    img = np.expand_dims(img, 0)\n",
        "    img = tensorflow.keras.applications.inception_v3.preprocess_input(img)\n",
        "    prediction = model.predict(img)[0]\n",
        "    return {labels[i]: float(prediction[i]) for i in range(len(prediction))}\n",
        "\n",
        "imputs = gr.inputs.Image(shape=(299, 299))\n",
        "\n",
        "outputs = gr.outputs.Label(num_top_classes=3, label='預測結果')\n",
        "\n",
        "grobj = gr.Interface(fn=classify, inputs=imputs, outputs=outputs, title='Inception物件偵測')\n",
        "grobj.launch()\n",
        "```\n",
        "**自動歌詞產生器(繁體)** \n",
        "```\n",
        "import gradio as gr\n",
        "grobj = gr.Interface.load(\"huggingface/uer/gpt2-chinese-lyric\", inputs=\"text\", outputs=\"text\")\n",
        "grobj.launch()\n",
        "\n",
        "!pip install opencc\n",
        "!pip install transformers\n",
        "\n",
        "import gradio as gr\n",
        "from opencc import OpenCC\n",
        "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
        "\n",
        "cc = OpenCC('s2twp')\n",
        "\n",
        "def lyric(text):\n",
        "    text_generator = TextGenerationPipeline(model, tokenizer)\n",
        "    ret = text_generator(text, max_length=100, do_sample=True)\n",
        "    return cc.convert(ret[0]['generated_text'])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ezlEBkcmV_k"
      },
      "source": [
        "### 手寫數字"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8VePQb3wHxs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p98f6Ykeznzi"
      },
      "source": [
        "from urllib.request import urlretrieve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAUk1uKR0it1"
      },
      "source": [
        "urlretrieve(\"https://gr-models.s3-us-west-2.amazonaws.com/mnist-model.h5\", \"mnist-model.h5\")\n",
        "model = tensorflow.keras.models.load_model(\"mnist-model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ub16UDGmeD7"
      },
      "source": [
        "### Inception辨識物體"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr6VXJXbSQ9M"
      },
      "source": [
        "import gradio as gr\n",
        "import tensorflow\n",
        "import numpy as np\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeFO9N77UZTN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpAFtzldsrwf"
      },
      "source": [
        "### 自動歌詞產生器(繁體)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G483ovQTUwzV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9onhdbl2phfV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kEXjO8QrCUB"
      },
      "source": [
        "grobj = gr.Interface(fn=lyric,inputs=\"textbox\", outputs=gr.outputs.Textbox(), title=\"自動產生歌詞\")\n",
        "grobj.launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh9QlsEzDLSy"
      },
      "source": [
        "## Teachable Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRnMVCzfJQ6B"
      },
      "source": [
        "### Teachable Machine程式碼\n",
        "```\n",
        "import numpy as np\n",
        "import cv2\n",
        "from time import sleep\n",
        "import tensorflow.keras\n",
        " \n",
        "labels = ['cloth','fist','nothing']\n",
        "current_x = 300\n",
        "move = 10\n",
        "model = tensorflow.keras.models.load_model('keras_model.h5')\n",
        " \n",
        "cap = cv2.VideoCapture(0)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "while True:\n",
        "    success, image = cap.read()\n",
        "    if success == True:\n",
        "        data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "        image = cv2.flip(image,1) #左右反轉\n",
        "        img = cv2.resize(image,(224,224))\n",
        "        img = np.array(img,dtype=np.float32)\n",
        "        img = np.expand_dims(img,axis=0)\n",
        "        img = (img/127.0) - 1 #正規化\n",
        "        data[0] = img\n",
        " \n",
        "        prediction = model.predict(data) #預測\n",
        "        predicted_class = np.argmax(prediction[0], axis=-1)\n",
        "        predicted_class_name = labels[predicted_class]\n",
        "        print(current_x, predicted_class_name)\n",
        " \n",
        "        if predicted_class_name == 'cloth':\n",
        "            current_x -= move\n",
        "            if current_x < 0:\n",
        "                current_x = 0\n",
        "        elif predicted_class_name == 'fist':\n",
        "            current_x += move\n",
        "            if current_x > width:\n",
        "                current_x = width\n",
        "        cv2.putText(image, 'O', (current_x,100), cv2.FONT_HERSHEY_PLAIN, 0.4, (255, 0, 0), cv2.LINE_AA)\n",
        "        cv2.imshow(\"Frame\",image)\n",
        "        sleep(0.2)\n",
        " \n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        " \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()    \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiV0V3mYPYpi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPydcJ8vQ8aD"
      },
      "source": [
        "## cvzone：多媒體機器學習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfxgP48AR_ns"
      },
      "source": [
        "### cvzone程式碼\n",
        "```\n",
        "!pip install cvzone\n",
        "!pip install mediapipe\n",
        "\n",
        "#臉部偵測\n",
        "from cvzone.FaceDetectionModule import FaceDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/person1.jpg')\n",
        "detector = FaceDetector()\n",
        "img, bboxs = detector.findFaces(img)\n",
        "#print('人臉範圍：', bboxs)\n",
        "cv2_imshow(img)\n",
        "\n",
        "#臉部特徵網\n",
        "from cvzone.FaceMeshModule import FaceMeshDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/person1.jpg')\n",
        "detector = FaceMeshDetector(staticMode=True, maxFaces=5)\n",
        "img, faces = detector.findFaceMesh(img)\n",
        "cv2_imshow(img)\n",
        "\n",
        "#手部偵測\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/hand1.jpg')\n",
        "detector = HandDetector(mode=False, detectionCon=0.5, maxHands=2)\n",
        "img = detector.findHands(img)\n",
        "cv2_imshow(img)\n",
        "\n",
        "#姿勢偵測\n",
        "from cvzone.PoseModule import PoseDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/pose1.jpg')\n",
        "detector = PoseDetector()\n",
        "img = detector.findPose(img)\n",
        "cv2_imshow(img)\n",
        "\n",
        "#手部攝影追踪\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "detector = HandDetector()\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    img = cv2.flip(img, 1)\n",
        "    img = detector.findHands(img)\n",
        "    cv2.imshow(\"Image\", img)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHhnlE4-RnwA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqqZbppTRF5C"
      },
      "source": [
        "#臉部偵測\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjlR0IY0RTx2"
      },
      "source": [
        "#臉部特徵網\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDfNTnaERX1i"
      },
      "source": [
        "#手部偵測\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uet0vG-1RzSm"
      },
      "source": [
        "#姿勢偵測\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDrFF6V8R3EB"
      },
      "source": [
        "#手部狀態偵測\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/hand1.jpg')\n",
        "detector = HandDetector(mode=False, detectionCon=0.5)\n",
        "img = detector.findHands(img)\n",
        "lmList, bboxInfo = detector.findPosition(img)\n",
        "#print('特徵點：', lmList)\n",
        "if lmList:\n",
        "  bbox = bboxInfo['bbox']\n",
        "  #左右手\n",
        "  myHandType = detector.handType() \n",
        "  cv2.putText(img, 'Hand:{}'.format(myHandType), (bbox[0], bbox[1]-25), cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), 2)\n",
        "  #伸出手指數\n",
        "  fingers = detector.fingersUp()\n",
        "  #print(fingers)\n",
        "  upFingers = fingers.count(1)\n",
        "  cv2.putText(img, 'Finger:{}'.format(upFingers), (bbox[0]+100, bbox[1]-25), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 2)\n",
        "  #兩特徵點距離\n",
        "  distance, img, info = detector.findDistance(8, 12, img) #食指與中指\n",
        "  cv2.putText(img, 'Dist:{}'.format(str(int(distance))), (bbox[0]+200, bbox[1]-25), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}