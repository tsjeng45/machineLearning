{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20210805機器學習教師研習.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aHuZ9JFphY0x",
        "ektmJJbyvtVk",
        "Oh9QlsEzDLSy"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHuZ9JFphY0x"
      },
      "source": [
        "## 手寫數字辨識"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo9SvX41qrkC"
      },
      "source": [
        "### 手寫數字辨識程式碼\n",
        "```\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(20, input_dim=784, activation='relu'))\n",
        "model.add(Dense(40, activation='relu'))\n",
        "model.add(Dense(80, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='mse', optimizer=SGD(learning_rate=0.05), metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, validation_split=0.2, batch_size=100, epochs=20)\n",
        "\n",
        "predict = np.argmax(model.predict(x_test), axis=-1)\n",
        "\n",
        "score = model.evaluate(x_test, y_test)\n",
        "print('正確率', score[1])\n",
        "\n",
        "model.save('number.h5')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY_PDGWwgVBX"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QpjtvzVhVmV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24681cb5-c016-461e-cbbb-b74e1b18dc85"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPi2fGtG-QTL",
        "outputId": "2321adae-c1ba-4e42-9786-35b0d24a7fd9"
      },
      "source": [
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAZjPI1q-2P-",
        "outputId": "00f93809-4cca-4ea1-9219-2194cfbc94e5"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq3lRGBC_Hdt",
        "outputId": "70965e59-ab63-4ff4-d70f-2b2125c1184d"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO5Egj31_WY9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ektmJJbyvtVk"
      },
      "source": [
        "## gradio：網頁互動界面"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UckXjSlv0Aux"
      },
      "source": [
        "### gradio程式碼\n",
        "**手寫數字**\n",
        "```\n",
        "!pip install gradio\n",
        "\n",
        "import gradio as gr\n",
        "import tensorflow\n",
        "\n",
        "model = tensorflow.keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/number.h5\")\n",
        "\n",
        "def mnist(image):\n",
        "    image = image.reshape(1, 784)\n",
        "    prediction = model.predict(image).tolist()[0]\n",
        "    return {str(i): prediction[i] for i in range(10)}\n",
        "\n",
        "grobj = gr.Interface(fn=mnist, inputs=\"sketchpad\", outputs=gr.outputs.Label(num_top_classes=3, label='預測結果'), title=\"手寫數字\")\n",
        "grobj.launch()\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "urlretrieve(\"https://gr-models.s3-us-west-2.amazonaws.com/mnist-model.h5\", \"mnist-model.h5\")\n",
        "model = load_model(\"mnist-model.h5\")\n",
        "```\n",
        "**Inception辨識物體**\n",
        "```\n",
        "import gradio as gr\n",
        "import tensorflow\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "model = tensorflow.keras.applications.InceptionV3()\n",
        "\n",
        "response = requests.get('https://git.io/JJkYN')\n",
        "\n",
        "labels = response.text.split('\\n')\n",
        "\n",
        "def classify(img):\n",
        "    img = np.expand_dims(img, 0)\n",
        "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "    prediction = model.predict(img)[0]\n",
        "    return {labels[i]: float(prediction[i]) for i in range(len(prediction))\n",
        "\n",
        "imputs = gr.inputs.Image(shape=(299, 299))\n",
        "\n",
        "outputs = gr.outputs.Label(num_top_classes=3, label='預測結果')\n",
        "\n",
        "grobj = gr.Interface(fn=classify, inputs=imputs, outputs=outputs, title='Inception物件偵測')\n",
        "grobj.launch()\n",
        "```\n",
        "**自動歌詞產生器(繁體)** \n",
        "```\n",
        "import gradio as gr\n",
        "grobj = gr.Interface.load(\"huggingface/uer/gpt2-chinese-lyric\", inputs=\"text\", outputs=\"text\")\n",
        "grobj.launch()\n",
        "\n",
        "!pip install opencc\n",
        "!pip install transformers\n",
        "\n",
        "import gradio as gr\n",
        "from opencc import OpenCC\n",
        "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
        "\n",
        "cc = OpenCC('s2twp')\n",
        "\n",
        "def lyric(text):\n",
        "    text_generator = TextGenerationPipeline(model, tokenizer)\n",
        "    ret = text_generator(text, max_length=100, do_sample=True)\n",
        "    return cc.convert(ret[0]['generated_text'])\n",
        "\n",
        "grobj = gr.Interface(lyric,inputs=\"textbox\", outputs=gr.outputs.Textbox(), title=\"自動產生歌詞\")\n",
        "grobj.launch()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ezlEBkcmV_k"
      },
      "source": [
        "### 手寫數字"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8VePQb3wHxs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84PstICRxy69"
      },
      "source": [
        "import gradio as gr\n",
        "import tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH3pREsMx8Kh"
      },
      "source": [
        "model = tensorflow.keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/number.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFFPFXd2yzt1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p98f6Ykeznzi"
      },
      "source": [
        "from urllib.request import urlretrieve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAUk1uKR0it1"
      },
      "source": [
        "urlretrieve(\"https://gr-models.s3-us-west-2.amazonaws.com/mnist-model.h5\", \"mnist-model.h5\")\n",
        "model = load_model(\"mnist-model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ub16UDGmeD7"
      },
      "source": [
        "### Inception辨識物體"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr6VXJXbSQ9M"
      },
      "source": [
        "import gradio as gr\n",
        "import tensorflow\n",
        "import numpy as np\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeFO9N77UZTN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mmXPX49Ui-x"
      },
      "source": [
        "grobj = gr.Interface(fn=classify, inputs=imputs, outputs=outputs, title='Inception物件偵測')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh3qyofTUs4G"
      },
      "source": [
        "grobj.launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpAFtzldsrwf"
      },
      "source": [
        "### 自動歌詞產生器(繁體)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G483ovQTUwzV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ofg7c1AovKV"
      },
      "source": [
        "!pip install opencc\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ25EZy4paXU"
      },
      "source": [
        "import gradio as gr\n",
        "from opencc import OpenCC\n",
        "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9onhdbl2phfV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kEXjO8QrCUB"
      },
      "source": [
        "grobj = gr.Interface(lyric,inputs=\"textbox\", outputs=gr.outputs.Textbox(), title=\"自動產生歌詞\")\n",
        "grobj.launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh9QlsEzDLSy"
      },
      "source": [
        "## Teachable Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRnMVCzfJQ6B"
      },
      "source": [
        "```\n",
        "import numpy as np\n",
        "import cv2\n",
        "from time import sleep\n",
        "import tensorflow.keras\n",
        "\n",
        "labels = ['cloth','fist','nothing']\n",
        "current_x = 300\n",
        "move = 10\n",
        "model = tensorflow.keras.models.load_model('keras_model.h5')\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "while True:\n",
        "    success, image = cap.read()\n",
        "    if success == True:\n",
        "        data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "        image = cv2.flip(image,1) #左右反轉\n",
        "        img = cv2.resize(image,(224,224))\n",
        "        img = np.array(img,dtype=np.float32)\n",
        "        img = np.expand_dims(img,axis=0)\n",
        "        img = (img/127.0) - 1 #正規化\n",
        "        data[0] = img\n",
        "\n",
        "        prediction = model.predict(data) #預測\n",
        "        predicted_class = np.argmax(prediction[0], axis=-1)\n",
        "        predicted_class_name = labels[predicted_class]\n",
        "        print(current_x, predicted_class_name)\n",
        "\n",
        "        if predicted_class_name == 'cloth':\n",
        "            current_x -= move\n",
        "            if current_x < 0:\n",
        "                current_x = 0\n",
        "        elif predicted_class_name == 'fist':\n",
        "            current_x += move\n",
        "            if current_x > width:\n",
        "                current_x = width\n",
        "        cv2.putText(image, 'O', (current_x,100), cv2.FONT_HERSHEY_PLAIN, 0.4, (255, 0, 0), cv2.LINE_AA)\n",
        "        cv2.imshow(\"Frame\",image)\n",
        "        sleep(0.2)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\t\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiV0V3mYPYpi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPydcJ8vQ8aD"
      },
      "source": [
        "## cvzone：多媒體機器學習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfxgP48AR_ns"
      },
      "source": [
        "### cvzone程式碼\n",
        "```\n",
        "#臉部偵測\n",
        "from cvzone.FaceDetectionModule import FaceDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/package/person1.jpg')\n",
        "detector = FaceDetector()\n",
        "img, bboxs = detector.findFaces(img)\n",
        "#print('人臉範圍：', bboxs)\n",
        "cv2_imshow(img)\n",
        "\n",
        "#臉部特徵網\n",
        "from cvzone.FaceMeshModule import FaceMeshDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/package/person1.jpg')\n",
        "detector = FaceMeshDetector(staticMode=True, maxFaces=5)\n",
        "img, faces = detector.findFaceMesh(img)\n",
        "cv2_imshow(img)\n",
        "\n",
        "#手部偵測\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/package/hand1.jpg')\n",
        "detector = HandDetector(mode=False, detectionCon=0.5, maxHands=2)\n",
        "img = detector.findHands(img)\n",
        "cv2_imshow(img)\n",
        "\n",
        "#姿勢偵測\n",
        "from cvzone.PoseModule import PoseDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/package/pose1.jpg')\n",
        "detector = PoseDetector()\n",
        "img = detector.findPose(img)\n",
        "cv2_imshow(img)\n",
        "\n",
        "#手部攝影追踪\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "detector = HandDetector(minTrackCon=0.5, maxHands=2)\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    img = cv2.flip(img, 1)\n",
        "    img = detector.findHands(img)\n",
        "    cv2.imshow(\"Image\", img)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHhnlE4-RnwA"
      },
      "source": [
        "!pip install cvzone\n",
        "!pip install mediapipe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqqZbppTRF5C"
      },
      "source": [
        "#臉部偵測\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjlR0IY0RTx2"
      },
      "source": [
        "#臉部特徵網\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDfNTnaERX1i"
      },
      "source": [
        "#手部偵測\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uet0vG-1RzSm"
      },
      "source": [
        "#姿勢偵測\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDrFF6V8R3EB"
      },
      "source": [
        "#手部狀態偵測\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/package/hand1.jpg')\n",
        "detector = HandDetector(mode=False, detectionCon=0.5)\n",
        "img = detector.findHands(img)\n",
        "lmList, bboxInfo = detector.findPosition(img)\n",
        "#print('特徵點：', lmList)\n",
        "if lmList:\n",
        "  bbox = bboxInfo['bbox']\n",
        "  #左右手\n",
        "  myHandType = detector.handType() \n",
        "  cv2.putText(img, 'Hand:{}'.format(myHandType), (bbox[0], bbox[1]-25), cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), 2)\n",
        "  #伸出手指數\n",
        "  fingers = detector.fingersUp()\n",
        "  #print(fingers)\n",
        "  upFingers = fingers.count(1)\n",
        "  cv2.putText(img, 'Finger:{}'.format(upFingers), (bbox[0]+100, bbox[1]-25), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 2)\n",
        "  #兩特徵點距離\n",
        "  distance, img, info = detector.findDistance(8, 12, img) #食指與中指\n",
        "  cv2.putText(img, 'Dist:{}'.format(str(int(distance))), (bbox[0]+200, bbox[1]-25), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFENo0BaLDx3"
      },
      "source": [
        "## Bonus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqmrAU7ZJPIk"
      },
      "source": [
        "!pip install git+https://github.com/Zeecka/pytube@fix_1060#egg=pytube\n",
        "!pip install google_trans_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua9-YYJoMBSO"
      },
      "source": [
        "!sed -i \"s/response = (decoded_line + ']')/response = decoded_line/g\" /usr/local/lib/python3.7/dist-packages/google_trans_new/google_trans_new.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ds02s84MHqs"
      },
      "source": [
        "from pytube import YouTube\n",
        "from google_trans_new import google_translator\n",
        "import re\n",
        "\n",
        "translator = google_translator()\n",
        "yt = YouTube('https://www.youtube.com/watch?v=3hRxS_As6-s')\n",
        "fname = yt.title\n",
        "fname = re.sub('[<>|?\"*:/]', '', fname)  #去除檔名中特殊字元\n",
        "fname = '/content/drive/MyDrive/Colab Notebooks/package/' + fname\n",
        "#print(yt.captions)\n",
        "if 'a.en' in yt.captions.keys():\n",
        "  yt.streams.filter(subtype='mp4', res='720p', progressive=True).first().download('/content/drive/MyDrive/Colab Notebooks/package/')\n",
        "  srt = yt.captions['a.en'].generate_srt_captions()\n",
        "  srtlist = srt.split('\\n')\n",
        "  for i in range(2, len(srtlist), 4):\n",
        "      srtlist[i] = translator.translate(srtlist[i], lang_src='en', lang_tgt='zh-TW')\n",
        "  srt_zh = '\\n'.join(srtlist)\n",
        "  file = open(fname + '.srt', 'w', encoding='Big5')\n",
        "  file.write(srt_zh)\n",
        "  file.close()\n",
        "  print('下載完成！')\n",
        "else:\n",
        "  print('沒有指定字幕！')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}