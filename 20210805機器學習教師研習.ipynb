{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20210805機器學習教師研習.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aHuZ9JFphY0x",
        "ektmJJbyvtVk",
        "Oh9QlsEzDLSy",
        "MPydcJ8vQ8aD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHuZ9JFphY0x"
      },
      "source": [
        "## 手寫數字辨識"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nAo8pCH-NT0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo9SvX41qrkC"
      },
      "source": [
        "### 手寫數字辨識程式碼\n",
        "```\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(20, input_dim=784, activation='relu'))\n",
        "model.add(Dense(40, activation='relu'))\n",
        "model.add(Dense(80, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='mse', optimizer=SGD(learning_rate=0.05), metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, validation_split=0.2, batch_size=100, epochs=20)\n",
        "\n",
        "predict = np.argmax(model.predict(x_test), axis=-1)\n",
        "\n",
        "score = model.evaluate(x_test, y_test)\n",
        "print('正確率', score[1])\n",
        "\n",
        "model.save('number.h5')\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/number.h5')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY_PDGWwgVBX"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QpjtvzVhVmV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c94828bc-0daa-4fef-a5a8-aea2eed5ef19"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfrsYzy7O1ZN",
        "outputId": "4715eb07-aa0f-4a85-8c1f-a42235ccad94"
      },
      "source": [
        "x_train"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdgmDqB4PFAo",
        "outputId": "5f24133a-d9d5-4c03-8bff-c87400043a54"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUHkQmD_PgLg",
        "outputId": "469d4b36-0700-46be-c196-c7631f43b247"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQcOHCQWPzQb",
        "outputId": "24a0d8b2-d2ff-4cc9-c6c6-fc07d6d4950f"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OISnyljqQP9e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxBi44T4P-Tw",
        "outputId": "eea16f14-4b4c-4174-cc0c-92daf8975153"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7Rs4SYSQRgq",
        "outputId": "78367304-32dc-4468-f0f5-f8a4369f599f"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "gvRjIWo1Qh8c",
        "outputId": "8389ed33-f63b-4ea0-cc67-074eaeee00b1"
      },
      "source": [
        "plt.imshow(x_train[0], cmap='binary')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fad85b24250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfMdWVaeQe5Y",
        "outputId": "51a07fd9-75ce-4940-a790-2c3265ed4f3b"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFQoxpf_SSnX"
      },
      "source": [
        "x_train = x_train.reshape(60000, -1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSoT4_TzSuNZ",
        "outputId": "6c51074f-ced1-4592-9836-22d5d7226360"
      },
      "source": [
        "t2.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTA3OJCoSxSV"
      },
      "source": [
        "x_test = x_test.reshape(10000, -1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4og6JduTY_W"
      },
      "source": [
        "x_train = x_train / 255\n",
        "x_test = x_test / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht7HCKFPYqnO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ektmJJbyvtVk"
      },
      "source": [
        "## gradio：網頁互動界面"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UckXjSlv0Aux"
      },
      "source": [
        "### gradio程式碼\n",
        "**手寫數字**\n",
        "```\n",
        "!pip install gradio\n",
        "\n",
        "import gradio as gr\n",
        "import tensorflow\n",
        "\n",
        "model = tensorflow.keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/number.h5\")\n",
        "\n",
        "def mnist(image):\n",
        "    image = image.reshape(1, 784)\n",
        "    prediction = model.predict(image).tolist()[0]\n",
        "    return {str(i): prediction[i] for i in range(10)}\n",
        "\n",
        "grobj = gr.Interface(fn=mnist, inputs=\"sketchpad\", outputs=gr.outputs.Label(num_top_classes=3, label='預測結果'), title=\"手寫數字\")\n",
        "grobj.launch()\n",
        "```\n",
        "**Inception辨識物體**\n",
        "```\n",
        "import gradio as gr\n",
        "import tensorflow\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "model = tensorflow.keras.applications.InceptionV3()\n",
        "\n",
        "response = requests.get('https://git.io/JJkYN')\n",
        "\n",
        "labels = response.text.split('\\n')\n",
        "\n",
        "def classify(img):\n",
        "    img = np.expand_dims(img, 0)\n",
        "    img = tensorflow.keras.applications.inception_v3.preprocess_input(img)\n",
        "    prediction = model.predict(img)[0]\n",
        "    return {labels[i]: float(prediction[i]) for i in range(len(prediction))}\n",
        "\n",
        "imputs = gr.inputs.Image(shape=(299, 299))\n",
        "\n",
        "outputs = gr.outputs.Label(num_top_classes=3, label='預測結果')\n",
        "\n",
        "grobj = gr.Interface(fn=classify, inputs=imputs, outputs=outputs, title='Inception物件偵測')\n",
        "grobj.launch()\n",
        "```\n",
        "**自動歌詞產生器(繁體)** \n",
        "```\n",
        "import gradio as gr\n",
        "grobj = gr.Interface.load(\"huggingface/uer/gpt2-chinese-lyric\", inputs=\"text\", outputs=\"text\")\n",
        "grobj.launch()\n",
        "\n",
        "!pip install opencc\n",
        "!pip install transformers\n",
        "\n",
        "import gradio as gr\n",
        "from opencc import OpenCC\n",
        "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
        "\n",
        "cc = OpenCC('s2twp')\n",
        "\n",
        "def lyric(text):\n",
        "    text_generator = TextGenerationPipeline(model, tokenizer)\n",
        "    ret = text_generator(text, max_length=100, do_sample=True)\n",
        "    return cc.convert(ret[0]['generated_text'])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ezlEBkcmV_k"
      },
      "source": [
        "### 手寫數字"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8VePQb3wHxs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p98f6Ykeznzi"
      },
      "source": [
        "from urllib.request import urlretrieve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAUk1uKR0it1"
      },
      "source": [
        "urlretrieve(\"https://gr-models.s3-us-west-2.amazonaws.com/mnist-model.h5\", \"mnist-model.h5\")\n",
        "model = tensorflow.keras.models.load_model(\"mnist-model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ub16UDGmeD7"
      },
      "source": [
        "### Inception辨識物體"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr6VXJXbSQ9M"
      },
      "source": [
        "import gradio as gr\n",
        "import tensorflow\n",
        "import numpy as np\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeFO9N77UZTN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpAFtzldsrwf"
      },
      "source": [
        "### 自動歌詞產生器(繁體)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G483ovQTUwzV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9onhdbl2phfV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kEXjO8QrCUB"
      },
      "source": [
        "grobj = gr.Interface(fn=lyric,inputs=\"textbox\", outputs=gr.outputs.Textbox(), title=\"自動產生歌詞\")\n",
        "grobj.launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh9QlsEzDLSy"
      },
      "source": [
        "## Teachable Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7AWUGRdPeZB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRnMVCzfJQ6B"
      },
      "source": [
        "### Teachable Machine程式碼\n",
        "```\n",
        "import numpy as np\n",
        "import cv2\n",
        "from time import sleep\n",
        "import tensorflow.keras\n",
        " \n",
        "labels = ['cloth','fist','nothing']\n",
        "current_x = 300\n",
        "move = 10\n",
        "model = tensorflow.keras.models.load_model('keras_model.h5')\n",
        " \n",
        "cap = cv2.VideoCapture(0)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "while True:\n",
        "    success, image = cap.read()\n",
        "    if success == True:\n",
        "        data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "        image = cv2.flip(image,1) #左右反轉\n",
        "        img = cv2.resize(image,(224,224))\n",
        "        img = np.array(img,dtype=np.float32)\n",
        "        img = np.expand_dims(img,axis=0)\n",
        "        img = (img/127.0) - 1 #正規化\n",
        "        data[0] = img\n",
        " \n",
        "        prediction = model.predict(data) #預測\n",
        "        predicted_class = np.argmax(prediction[0], axis=-1)\n",
        "        predicted_class_name = labels[predicted_class]\n",
        "        print(current_x, predicted_class_name)\n",
        " \n",
        "        if predicted_class_name == 'cloth':\n",
        "            current_x -= move\n",
        "            if current_x < 0:\n",
        "                current_x = 0\n",
        "        elif predicted_class_name == 'fist':\n",
        "            current_x += move\n",
        "            if current_x > width:\n",
        "                current_x = width\n",
        "        cv2.putText(image, 'O', (current_x,100), cv2.FONT_HERSHEY_PLAIN, 0.4, (255, 0, 0), cv2.LINE_AA)\n",
        "        cv2.imshow(\"Frame\",image)\n",
        "        sleep(0.2)\n",
        " \n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        " \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()    \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiV0V3mYPYpi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPydcJ8vQ8aD"
      },
      "source": [
        "## cvzone：多媒體機器學習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfxgP48AR_ns"
      },
      "source": [
        "### cvzone程式碼\n",
        "```\n",
        "!pip install cvzone\n",
        "!pip install mediapipe\n",
        "\n",
        "#臉部偵測\n",
        "from cvzone.FaceDetectionModule import FaceDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/person1.jpg')\n",
        "detector = FaceDetector()\n",
        "img, bboxs = detector.findFaces(img)\n",
        "#print('人臉範圍：', bboxs)\n",
        "cv2_imshow(img)\n",
        "\n",
        "#臉部特徵網\n",
        "from cvzone.FaceMeshModule import FaceMeshDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/person1.jpg')\n",
        "detector = FaceMeshDetector(staticMode=True, maxFaces=5)\n",
        "img, faces = detector.findFaceMesh(img)\n",
        "cv2_imshow(img)\n",
        "\n",
        "#手部偵測\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/hand1.jpg')\n",
        "detector = HandDetector(mode=False, detectionCon=0.5, maxHands=2)\n",
        "img = detector.findHands(img)\n",
        "cv2_imshow(img)\n",
        "\n",
        "#姿勢偵測\n",
        "from cvzone.PoseModule import PoseDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/pose1.jpg')\n",
        "detector = PoseDetector()\n",
        "img = detector.findPose(img)\n",
        "cv2_imshow(img)\n",
        "\n",
        "#手部攝影追踪\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "detector = HandDetector()\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    img = cv2.flip(img, 1)\n",
        "    img = detector.findHands(img)\n",
        "    cv2.imshow(\"Image\", img)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHhnlE4-RnwA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqqZbppTRF5C"
      },
      "source": [
        "#臉部偵測\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjlR0IY0RTx2"
      },
      "source": [
        "#臉部特徵網\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDfNTnaERX1i"
      },
      "source": [
        "#手部偵測\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uet0vG-1RzSm"
      },
      "source": [
        "#姿勢偵測\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDrFF6V8R3EB"
      },
      "source": [
        "#手部狀態偵測\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/hand1.jpg')\n",
        "detector = HandDetector(mode=False, detectionCon=0.5)\n",
        "img = detector.findHands(img)\n",
        "lmList, bboxInfo = detector.findPosition(img)\n",
        "#print('特徵點：', lmList)\n",
        "if lmList:\n",
        "  bbox = bboxInfo['bbox']\n",
        "  #左右手\n",
        "  myHandType = detector.handType() \n",
        "  cv2.putText(img, 'Hand:{}'.format(myHandType), (bbox[0], bbox[1]-25), cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), 2)\n",
        "  #伸出手指數\n",
        "  fingers = detector.fingersUp()\n",
        "  #print(fingers)\n",
        "  upFingers = fingers.count(1)\n",
        "  cv2.putText(img, 'Finger:{}'.format(upFingers), (bbox[0]+100, bbox[1]-25), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 2)\n",
        "  #兩特徵點距離\n",
        "  distance, img, info = detector.findDistance(8, 12, img) #食指與中指\n",
        "  cv2.putText(img, 'Dist:{}'.format(str(int(distance))), (bbox[0]+200, bbox[1]-25), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}